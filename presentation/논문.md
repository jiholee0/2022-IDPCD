# 사용자 손 제스처 인식 기반 키오스크 제어 시스템
Kiosk control system based on user hand gesture recognition

## 요약
> 정전식 터치패드로 동작하는 기존의 키오스크는 시력 저하와 같은 신체적 노화, 기계에 대한 부정적 인식 등으로 인해 노인에게 불편함을 초래한다. 본 논문은 손 제스처로 키오스크를 제어함으로써 노인이나 시각장애인을 포함한 모든 사용자가 키오스크를 부담 없이 이용할 수 있는 시스템을 제안한다. 키오스크마다 주문 시 필요한 동작이 천차만별이므로, 노인에게 적합한 키오스크 모니터 화면을 가상으로 구성하고, 각 동작을 제스처와 매칭한다. 키오스크 제어의 경우 소켓 통신과 openCV 이미지 출력 함수를 이용하여 인식한 제스처에 따라 이미지(키오스크 화면)가 출력되는 환경을 구성한다. 카메라의 각도, 사용자와의 거리 조건을 조합하여 실험한 결과, 키오스크 모니터 아래에 카메라를 부착한 후 15cm 이내 거리의 조건 하에서 인식률이 99.34%로 가장 높은 것을 확인하였다.

## 키워드
> 제스처 인식, 키오스크 제어, 노인, 미디어파이프, 오픈씨브이, k-최근접 알고리즘

## 1장. 서론
> '키오스크(kiosk)'란 정보 서비스와 업무의 무인자동화를 통해 대중이 쉽게 이용할 수 있도록 공공장소에 설치한 무인 단말기를 말하며, 정식 명칭은 인터렉티브 키오스크이다. 대개 터치 스크린이 탑재되어 있어 화면에 출력되는 안내 글자를 읽고 해당 글자(버튼)을 터치하는 방식으로 동작한다.

> 키오스크는 주로 음식점과 같은 매장에서 적극적으로 활용하는데, 그 배경은 다음과 같다. 우선 업주 관점에서는 주문을 받는 인력이 불필요해지므로 직원들을 다른 업무에 투입시켜 업무 효율을 높이고 인건비를 절감할 수 있다. 직원의 실수로 손님의 요청사항을 헷갈려하거나 잊어버리는 위험 부담을 줄일 수도 있다. 손님 관점에서는 말을 하기 어려운 내성적인 경우 또는 발화 관련 장애가 있는 경우, 굳이 대화를 하지 않아도 주문이 가능해 편리하다. 또 해당 나라의 언어에 서툰 경우, 언어 전환 기능을 이용하면 편리하게 주문이 가능하다.

> 이러한 장점들로 인해 키오스크의 비중이 점점 늘어나고 있다. 주요 패스트푸드 기업인 K사는 2018년 전국 모든 매장에 키오스크를 도입하겠다는 계획을 달성했다. K사 관계자는 "키오스크 100% 도입으로 접객 직원을 매장 위생관리나 조리 등으로 돌려 보다 효율적으로 인력을 운영할 수 있게 됐다"며 키오스크에 긍정적인 인식을 갖고 있다.

> 그러나 키오스크가 마냥 긍정적인 면만 갖고 있는 것은 아니다. 분할 결제 및 현금 결제가 불가능하다는 점, 터치 인식률이 낮다는 점, 키오스크마다 결제 방식과 주문 방식이 천차만별이어서 통일성이 낮다는 점 등의 기기적 측면에서의 문제점이 존재한다. 키오스크를 통해 직원과의 대면 없이 복잡한 주문까지 쉽게 행하는 젊은층과 중년층들과는 달리, 노년층, 휠체어를 탄 장애인, 시각장애인 등의 사용자들은 이용에 어려움을 겪는다는 접근성 측면에서의 문제점도 존재한다. 이 외에도 불필요하게 복잡하고 비직관적인 UI, 작은 글씨, 광고 등 주문을 방해하는 요소들, 실업 문제 등 여러 부정적인 면을 갖고 있다.

> 표 1은 서울디지털재단이 발표한 ‘서울시민 디지털역량 실태조사’ 결과를 나타낸 것이다. 만 55세 이상 고령층의 디지털 기술 이용 수준은 100점 만점에 43.1점으로 서울 시민 전체 평균인 64.1점에 비해 32.7% 낮다. 고령층의 54.2%가 ‘키오스크를 단 한 번도 사용해본 적 없다’고 응답했으며, 75세 이상은 13.8%만이 키오스크 사용 경험이 있는 것으로 보아 나이가 들수록 키오스크 이용 경험은 줄어드는 것을 알 수 있다.

> 이에 본 논문에서는 연령에 따른 디지털 격차를 해소하고자 글씨가 읽지 않아도 키오스크를 이용할 수 있는 시스템을 제안한다. 제안하는 시스템은 제스처 인식 기술을 이용하여 사용자의 특정한 동작을 인식하고 키오스크 화면을 접촉 없이 제어한다. 노인이나 시각장애인을 포함한 모든 사용자는 글자를 읽고 해당 글자를 터치하는 것 대신, 글자를 보거나 듣고 적절한 손동작을 취하는 것으로 키오스크를 이용할 수 있다.

> 제스처 인식 기술은 인간-컴퓨터 상호작용 기술의 하나로서 인식에 사용되는 장비의 형태로 보면 크게 두 가지로 나눌 수 있다.[1] 하나는 카메라를 이용한 비전 기반 기술로서 주로 컴퓨터를 이용하여 하드웨어 장비를 제어한다.[2] 다른 형태는 동작 센서를 이용하는 기술로서 주로 리모컨에 센서를 부착하여 입력 장치로 활용하거나, 데이터 글로브를 착용하여 컴퓨터 화면을 제어한다.[3] 본 논문에서는 카메라를 이용하여 사용자의 제스처를 인식하는 방법을 제안한다.

[1] 장문수, 곽선동, 강선미 "제스처 인식과 센서를 이용한 프레젠테이션 제어 시스템" 한국지능시스템학회 논문지 2011, Vol. 21, No. 4, pp. 481-486

[2] 장문수, 곽선동, 강선미 "제스처 인식과 센서를 이용한 프레젠테이션 제어 시스템" 한국지능시스템학회 논문지 2011, Vol. 21, No. 4, pp. 481-486

[3] 장문수, 곽선동, 강선미 "제스처 인식과 센서를 이용한 프레젠테이션 제어 시스템" 한국지능시스템학회 논문지 2011, Vol. 21, No. 4, pp. 481-486

> 2장에서는 키오스크가 가진 문제점을 분석하고 이를 토대로 구성한 UI에 대해서 기술하고, 3장에서는 본 논문에서 제안하는 시스템에 사용되는 제스처 인식 알고리즘에 대해, 4장에서는 제안하는 알고리즘을 적용한 키오스크 제어 시스템의 구성과 동작 방식에 대해서 설명하고, 실험을 통해 제안하는 시스템의 최적화된 조건을 탐색하고 증명한다.

## 2장. 키오스크 UI
> 권오상 울산과학기술원(UNIST) 바이오메디컬공학과 교수는 “사람은 나이가 들면서 시각, 인지 기능이 자연스럽게 줄어든다.”며 “그 중 하나는 시각정보가 좁은 공간에 여러 개 있을 때 이를 명확하게 인지하지 못하는 ‘비주얼 크라우딩(시각적 혼잡)’이다.”라고 말했다. 미국 앨라배마대 연구팀에 따르면 고령층이 문장을 읽어내는 속도는 청년층보다 약 30% 느리고, 글자를 인식하기 위해 자간은 약 31% 더 넓어야 한다. 즉, 고령층은 글자를 읽어내는 속도가 느리고, 밀집된 글자를 인식하기 어렵다. 작은 화면에 많은 정보가 담긴 키오스크를 이용할 때는 비주얼 크라우딩이 더 크게 나타난다. 키오스크는 기본적으로 터치스크린 방식을 적용하여 스크린 속 글자가 곧 버튼으로 동작한다. 노인과 시각장애인을 비롯한 글자를 읽고 해석하는 것이 어려운 사용자들은 키오스크에 불편함을 느낀다.

> 이 점을 고려하여 본 논문에서는 노인에게 적합한 키오스크 스크린 UI를 가상으로 구성하였다. 한 화면 안에서 보여지는 정보를 최대한 줄이고, 한 가지만 질문한다. 불필요한 정보들을은 제거하고, 글씨는 크고 굵게 디자인하여 화면을 최대한 간결하게 만든다. 외래어는 최대한 우리 말로 순화하고, 이해를 돕기 위해 사진과 그림을 적극적으로 활용한다.

> 그림 1은 본 논문에서 사용한 키오스크 화면 UI 및 동작 순서도이다.

## 3장. 제스처 인식 알고리즘
> 본 논문에서는 카메라를 이용하여 사용자의 손 영상을 입력 받고, 제스처 종류를 인식하여 해당 동작을 수행하는 기능을 구현하였다. 우선, 손을 인식하여 좌표 정보를 입력받기 위해 Google에서 제공하는 오픈소스 모델인 MediaPipe의 Hands 솔루션을 사용하였다. 그리고 k-NN 알고리즘을 이용한 학습 모델을 이용하여 0 ~ 2까지의 숫자와 GOOD, OK와 같은 의미가 전달될 수 있는 제스처까지 인식할 수 있도록 구현하였다. 이렇게 구현된 손 제스처 인식모델의 출력을 이용하여 키오스크 화면 전환 기능을 구현할 수 있도록 하였다. 해당 내용은 4장에서 다루겠다.

3.1 미디어파이프(MediaPipe)
> 손 제스처를 인식하기 위하여 사용된 MediaPipe는 실시간 미디어를 위한 머신러닝 솔루션이다. Android, iOS, Windows 등 여러 운영체제에서 동작하며 C++, Python, JS 등의 다양한 프로그래밍 언어들로 구현이 되어있어 활용도가 높다. 3만장 이상의 손 영상 학습으로 인한 높은 정확도와 빠른 처리 속도가 특징이며, 간단한 임베디드 장치에서도 사용이 가능하다. 본 논문에서는 Mediapipe를 통해 손의 좌표 정보가 담긴 모델을 구현하였다.

3.2 k-NN(k-Nearest Neighbor) 기반의 손 제스처 인식
> k-NN(k-Nearest Neighbor) 알고리즘은 머신러닝의 지도학습 알고리즘의 한 종류로, 특징 공간에서 테스트 데이터와 가장 가까이 있는 k개의 학습 데이터를 찾아 분류 또는 회귀를 수행한다. 다른 머신러닝 알고리즘과 달리 데이터 자체를 학습 모델로 사용하여 학습 데이터는 있지만 학습 단계가 없는 것이 특징이다. 본 논문에서는 해당 알고리즘을 사용하여 입력받은 손 제스처 데이터와 저장된 학습용 데이터를 비교하여 가장 유사한 제스처 종류를 찾아낸다.

3.3 데이터 수집
> 손 제스처 인식을 위한 사전 학습 데이터를 구축하였다. 카메라로부터 영상을 입력받아 Mediapipe 프레임워크를 통해 그림 1과 같이 손가락의 21개 관절 지점 즉 손가락 마디의 좌표(x, y, z)값을 입력 받는다. 입력된 손의 좌표값은 식(1)에 따라 인접한 손 마디의 벡터를 구할 수 있으며, 식(1)에 따라 인접한 손 마디에 연결된 벡터 과 를 이용하여 손가락 마디 사이의 각도를 계산할 수 있다.

> 식(2)에 따라 각각의 인접한 손가락 마디의 단위 벡터를 이용하여 각도 를 계산한 후 단위를 radian에서 degree로 변환 후 손가락 마디의 각도 15개를 출력한다. 손 가락 마디 사이의 각도와 그 각도에 대응하는 제스처의 번호를 csv파일에 저장하여 Training data를 구성하였다. 그림 2에서 A~O열에는 인접한 손가락 마디 사이의 각도가 저장되며, P열에는 손 제스처 인식 숫자가 저장된다. 이렇게 저장된 학습 데이터를 기반으로 실시간으로 입력받은 손 제스처의 종류를 구분할 수 있도록 k-NN 알고리즘을 사용하여 구현하였다. 실시간으로 손의 좌표를 입력받아 각도를 계산하고, 저장된 학습 데이터에서 가장 인접한 데이터의 제스처 종류를 값으로 출력한다.

> 그림 3과 같이 Mediapipe를 이용하여 Training data를 csv 파일 형태로 생성을 하고 실제 카메라 입력 시 사용자 손 제스처 인식 과정을 수행한다. 실시간으로 입력된 이미지에서 계산된 각도를 이용하여 k-NN 알고리즘을 거쳐서 해당 손 제스처 값을 출력한다. 이 과정에서는 k-NN 객체를 생성하여 train함수에 학습 데이터 angle과 gesture를 입력하여 학습한다. 그리고 실시간으로 계산한 15개의 각도 값들을 data 변수에 입력하여 이웃의 값을 찾는 함수에 입력한다. 여기서 k값은 학습 데이터에서 비교할 가장 가까운 값의 개수인데, 손 제스처 모델의 적절한 성능을 위하여 k는 3으로 지정한다. 이에 따라 실시간으로 입력받은 손 이미지의 인접 관절 각도 값들은 학습 데이터에 저장된 각도 값들 중에서 가장 가까운 값 3개를 선택하여 해당 손 제스처를 출력한다. 이미지 입력부터 손 제스처 인식까지 실시간 손 제스처 입력 영상을 이용하여 손 제스처 인식 프로그램이 종료될 때까지 인식할 수 있도록 구현하였다. 그림 4는 카메라에 입력받는 손 제스처 영상을 인식한 결과 화면으로 숫자 0 ~ 2까지 GOOD, OK 와 같은 의미를 나타내는 손 제스처 인식 결과를 확인할 수 있다.


## 4장. 시스템 구현 및 실험
4.1 키오스크 제어 알고리즘
> 본 논문에서 구현하는 시스템에서는 키오스크에서 빈번하게 사용되는 페이지 넘김, 예, 아니오, 선택지 고르기, 네 가지 제어 동작을 제스처로 실현한다. 각 제어 명령에 대응하는 제스처를 표 1에 나타내고 있다.

> 명령에 해당하는 제스처는 동작 주체가 노인이라는 점을 고려하여 하기 쉬운 제스처로 선정한다. 노인의 경우 전신으로 제스처를 취하기 보다는 손으로, 두 손보다는 한 손으로 제스처를 취하는 것이 쉬우며, 손놀림의 정확성이 떨어져 단추를 채우거나 글씨를 쓰는 등의 세밀한 동작은 어렵다. 복잡하거나 손에 힘이 많이 들어가는 동작들보다는 간단하고 일상에서 자주 쓰이는 동작으로 한다.

> 시스템의 제스처 인식부에서는 제스처 인식을 위하여 그림 6에 나타낸 것과 같은 4가지 상태, 즉 입력대기 상태, 분석 상태, 전달 상태, 동작처리 상태를 반복한다. 입력대기 상태에서는 카메라로 들어온 영상에서 인식된 제스처의 수가 50개 이상이면 입력 상태로 넘어간다. 그렇지 않을 경우에는 계속 입력대기 상태에서 제스처를 확인한다. 분석 상태에서는 약 2초간 입력받은 50개의 제스처 중 가장 빈도 수가 높은 값을 결과로 하여 동작 처리를 위해 전달한다. 동작처리 상태에서는 화면마다 입력받을 제스처의 종류가 정해져있으므로, 만약 제스처가 올바르지 않으면 제스처를 인식하지 않은 것으로 간주하여 입력 대기 상태로 돌아간다. 올바른 제스처가 입력될 경우 해당 제스처에 따라 정해놓은 동작을 처리한다.

4.2 소켓 통신 기반 키오스크 제어 가상 설계
> 사용자 손 제스처 인식 알고리즘과 가상 키오스크와의 연동을 통하여 키오스크 제어 시스템을 설계 및 구현하였다. 파이썬으로 서버와 클라이언트가 서로 특정 포트로 연결되어 실시간으로 양방향 소통하며 제스처 인식 결과와 키오스크 제어 결과를 주고 받는 간단한 제어 시스템을 구현하였다.

4.3 실험 및 결과 분석
> 본 논문에서는 제안하는 시스템의 최적화된 조건을 확인하고자 각기 다른 조건 하에서 인식률 실험을 실시하였다. 실험은 각기 다른 조건을 설정하고 해당 조건 하에서 특정 제스처를 취한 후, 예상 결과와 비교하는 방식으로 수행하였다. 그림 5(?)는 실험 내에서 제스처 비교 및 실험 결과(인식률, 불일치율, 실패율) 출력 기능을 담당한 코드이다. 실험의 조건은 표 5와 같다.

4.3.1 손 각도에 따른 인식률 실험
> 키오스크에 부착될 카메라의 위치에 따라 보여지는 손의 각도가 다르므로 이에 따른 인식률을 비교하여 최적의 위치를 찾고자 하였다. 실험 결과, 표 @에 나타낸 것처럼 ~~

4.3.2 거리에 따른 인식률 실험
> 사용자마다 키오스크 모니터 및 카메라와의 거리가 다르므로 이에 따른 인식률을 비교하여 최적의 위치를 찾고자 하였다. 실험 결과, 표 @에 나타낸 것처럼 ~~

4.3.3 손 방향에 따른 인식률 실험
> 손등, 손바닥, 왼손, 오른손에 따라 인식률이 달라지는지 실험하여 성능을 확인하였다. 실험 결과, 표 @에 나타낸 것처럼 ~~

> 위 실험들을 종합해보았을 때, 최적의 조건은 다음과 같다. ~~~ . 또 세 번째 실험을 통해


## 5장. 결론
> 본 논문은 실시간 손 제스처 인식을 위하여 오픈소스 프레임워크인 MediaPipe 를 활용하여 사용자 손 관절 정보를 획득한 후 머신러닝 k-NN 기법을 활용하여 생성된 학습 모델을 기반으로 구현한 실시간 사용자 손 제스처 인식 알고리즘을 제안하였고, 사용자 인터랙션과 연동이 가능한 소켓 통신 기반 키오스크 제어 시스템을 제안하였다. 본 논문에서는 시스템의 최적 조건을 탐색하기 위하여 방향, 거리, 각도에 따라 실험하였고, 그 결과 @@@ 조건에서 가장 높은 인식률 @@를 얻었다.

> 향후 사용자 손 제스처 인식 알고리즘은 단순 손 제스처 의미 인식에서 손가락의 상대적인 위치 및 영상 내 객체 연동을 고려하여 복잡한 순서도를 가진 키오스크에도 적용할 수 있는 제스처 인식 알고리즘 연구를 진행할 필요가 있다. 본 연구를 통해 노인, 시각장애인 등도 키오스크를 어려움 없이 사용할 수 있게 되어 디지털 격차가 해소되기를 기대한다.