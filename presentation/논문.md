# 사용자 손 제스처 인식 기반 키오스크 제어 시스템

## 요약
> 정전식 터치패드로 동작하는 기존의 키오스크는 시력 저하와 같은 신체적 노화, 기계에 대한 부정적 인식 등으로 인해 노인에게 불편함을 초래한다. 본 논문은 카메라를 통한 손 제스처 인식을 이용하여 키오스크를 제어함으로써 노인이나 시각장애인을 포함한 모든 사용자가 키오스크를 부담 없이 이용할 수 있는 시스템을 제안한다. 키오스크마다 주문 시 필요한 동작이 천차만별이므로, 본 논문에서는 노인에게 적합한 키오스크 모니터 화면을 가상으로 구성하고, 각 동작을 제스처와 매칭하였다. +실험결과 요약
본 연구를 통해 노인, 시각장애인 등도 키오스크를 어려움 없이 사용할 수 있게 되어 디지털 격차가 해소되기를 기대한다.

## 키워드
> 제스처 인식, 키오스크 제어, 노인, 디지털 격차

## 1장. 서론
> '키오스크(kiosk)'는 정보 서비스와 업무의 무인자동화를 통해 대중이 쉽게 이용할 수 있도록 공공장소에 설치한 무인 단말기로, 인터렉티브 키오스크라고 한다. 대개 터치 스크린이 탑재되어 있어 화면에 출력되는 안내 화면을 보고 버튼을 클릭하는 방식으로 동작한다.

> 키오스크의 이러한 동작 방식은 업주와 손님에게 긍정적이다. 우선 업주 입장에서 보면 주문을 받는 인력이 불필요해지므로 직원들을 다른 업무에 투입시켜 업무 효율을 높이고 인건비를 절감할 수 있다. 또한, 복잡한 주문의 경우 직원의 실수로 손님의 요청사항을 헷갈려하거나 잊어버리는 위험 요소를 줄일 수 있다. 손님 입장에서 보면 말을 하기 어려운 내성적인 사람 또는 발화 관련 장애가 있는 사람은 굳이 대화를 하지 않아도 주문이 가능해 편리하다. 또한 해당 나라의 언어에 서툰 손님의 경우, 언어 전환 기능을 이용하면 편리하게 주문이 가능하다.

> 이러한 장점들로 인해 키오스크의 비중은 점점 늘어나고 있다. 주요 패스트푸드 기업인 K사는 2017년 전국 모든 매장에 키오스크를 도입한다고 선언한 뒤, 1년 만인 2018년에 이를 달성했다. 매장당 3~4대를 운영하고 있으며, K사 관계자는 "키오스크 100% 도입으로 접객 직원을 매장 위생관리나 조리 등으로 돌려 보다 효율적으로 인력을 운영할 수 있게 됐다"며 키오스크에 긍정적인 인식을 갖고 있다.

> 그러나 키오스크가 마냥 긍정적인 면만 갖고 있는 것은 아니다. 기기적 측면에서는 분할 결제가 불가능하다는 점, 터치 인식률이 낮다는 점, 키오스크마다 결제 방식과 주문 방식이 천차만별이어서 통일성이 낮다는 점, 현금 결제 지원이 되지 않는다는 점 등 문제점이 존재한다. 접근성 측면에서는 키오스크를 통해 직원과의 대면 없이 복잡한 주문까지 쉽게 행하는 젊은층과 중년층들과는 달리, 노년층, 휠체어를 탄 장애인, 시각장애인 등의 사용자들은 이용에 어려움을 겪는다는 문제점이 있다. 이 외에도 불필요하게 복잡하고 비직관적인 UI, 작은 글씨, 광고 등 주문을 방해하는 요소들, 실업 문제 등 여러 단점이 있다.

> 서울디지털재단이 16일 발표한 ‘서울시민 디지털역량 실태조사’ 결과에 따르면 서울에 사는 만 55세 이상 고령층의 디지털 기술 이용 수준은 43.1점(100점 만점)으로 서울 시민 전체 평균(64.1점) 대비 32.7% 낮았다. 또한, 키오스크 주문 시스템과 관련해 고령층의 54.2%는 ‘단 한 번도 사용해본 적 없다’고 응답했다. 나이가 들수록 키오스크 이용 경험은 줄어들어 75세 이상은 13.8%만이 키오스크를 사용한 경험이 있는 것으로 나타났다.

> 본 논문에서는 연령에 따른 디지털 격차를 해결하기 위해 글씨가 보이지 않아도 키오스크를 이용할 수 있는 시스템을 제안한다. 제안하는 시스템은 제스처 인식 기술을 이용하여 사용자의 특정한 동작을 인식하고 키오스크 화면을 제어한다.

> 제스처 인식 기술은 인간-컴퓨터 상호작용 기술의 하나로서 인식에 사용되는 장비의 형태로 보면 크게 두 가지로 나눌 수 있다. 하나는 카메라를 이용한 비전 기반 기술로서 컴퓨터를 이용하여 하드웨어 장비를 제어하기도 하고, 최근에는 로봇과의 상호작용에 관한 연구가 많이 진행되고 있다. 다른 형태는 동작 센서를 이용하는 기술로서 데이터 글로브(data glove)를 착용하여 컴퓨터 화면을 제어하거나, 리모컨에 센서를 부착하여 비디오 게임기의 입력 장치로 활용하거나 가정용 AV기기의 조작에 활용하기도 한다. 본 논문에서는 카메라를 이용한 영상 처리 기법을 이용하여 사용자의 제스처를 인식하는 방법을 제안한다.

> 2장에서는 키오스크가 가진 문제점을 분석하고 이를 토대로 구성한 UI에 대해서 기술하고, 3장에서는 본 논문에서 제안하는 시스템에 사용되는 제스처 인식 알고리즘에 대해, 4장에서는 제안하는 알고리즘을 적용한 키오스크 제어 시스템의 구성과 동작 방식에 대해서 설명하고 실험을 통해서 제안하는 시스템의 최적화된 조건을 탐색하고 증명한다.

## 2장. 키오스크 UI
> 권오상 울산과학기술원(UNIST) 바이오메디컬공학과 교수는 “사람은 나이가 들면서 시각, 인지 기능이 자연스럽게 줄어든다”며 “그중 하나는 시각정보가 좁은 공간에 여러 개 있을 때 이를 명확하게 인지하지 못하는 ‘비주얼 크라우딩(시각적 혼잡)’”이라고 말했다. 미국 앨라배마대 연구팀에 따르면 고령층이 짧은 문장을 읽어내는 속도는 젊은층보다 약 30% 느리다. 글자를 인식하기 위해 필요한 자간도 31% 넓어야 한다. 고령층은 정보를 읽어내는 속도가 느리고, 밀집된 정보를 해석하기 어렵다는 의미이다. 키오스크를 이용할 때는 더 큰 비주얼 크라우딩이 나타난다. 화면의 크기는 작으면서도 많은 정보가 담겨있기 때문이다. 글자 크기는 작고 자간은 좁아 화면을 읽어내는 데 느끼는 어려움은 더 커진다. 키오스크는 기본적으로 터치스크린 방식을 적용하여 업무를 처리한다. 글자를 보고 해석한 후 원하는 글자를 터치해야 한다. 따라서 노인과 시각장애인을 비롯하여 글자를 읽고 해석하는 것이 어려운 사람들은 키오스크를 다루는 것이 쉽지 않다.

> 따라서 본 논문에서는 노인에게 적합한 키오스크 스크린 UI를 가상으로 구성하여 활용하였다. 한 화면 안에서 최대한 적은 정보만을 전달하고, 한 가지만을 묻는다. 불필요한 정보들을은 제거하고, 글씨는 크고 굵게 디자인하여 화면을 최대한 간결하게 만들었다. 또한 노인들에게 생소할 수 있는 외래어를 사용할 때에는 최대한 우리 말로 순화하였고, 이해를 돕기 위해 사진과 그림을 적극적으로 활용하였다.

## 3장. 제스처 인식 알고리즘
> 본 논문에서는 카메라를 이용하여 손 제스처를 입력하고, 손 제스처 종류를 인식하여 값을 출력하는 기능을 구현하였다. 우선, 손을 인식하여 좌표 정보를 입력받기 위해 Google에서 제공하는 오픈소스 모델인 MediaPipe의 Hands 솔루션을 사용하였다. 그리고 k-NN 알고리즘을 이용한 학습 모델을 이용하여 0 ~ 2까지의 숫자와 GOOD, OK와 같은 의미가 전달될 수 있는 제스처까지 인식할 수 있도록 구현하였다. 이렇게 구현된 손 제스처 인식모델의 출력을 이용하여 키오스크에 대한 제어 기능을 구현할 수 있도록 하였다.

3.1 미디어파이프(MediaPipe)
> 손 제스처를 인식하기 위하여 사용된 MediaPipe는 실시간 미디어를 위한 머신러닝 솔루션이다. Android, iOS, Windows 등 여러 OS에서 동작하며 C++, Python, JS 등의 여러 언어들로 구현이 되어있기 때문에, 여러 방면에서 활용도가 높다. 또한, 3만장 이상의 손 영상을 사용한 학습으로 정확도가 높으며, 속도 또한 빨라 간단한 임베디드 장치에서도 사용이 가능하다. 본 논문에서는 Mediapipe를 통해 사용자 손 위치나 좌표와 같이 신체에 대한 특징점을 이용하여 손의 좌표 정보를 이용하여 모델을 구현하였다.

3.2 k-NN(k-Nearest Neighbor) 기반의 손 제스처 인식
> k-NN은 머신러닝의 지도학습 알고리즘의 한 종류로, 특징 공간에서 테스트 데이터와 가장 가까이 있는 k개의 학습 데이터를 찾아 분류 또는 회귀를 수행한다. 다른 머신러닝 모델과 달리 데이터 자체를 학습 모델로 사용하기 때문에, 학습 데이터는 있지만, 학습 단계가 따로 없다. 따라서 본 논문에서 구현한 손 제스처 모델에서는 이 알고리즘을 사용하여 입력받은 손 제스처에 대한 데이터와 저장된 학습용 데이터를 비교하여 가장 유사한 제스처 종류를 찾아낸다.

3.3 데이터 수집
> 선 손 제스처 인식을 위하여 사전 학습된 데이터를 구축하는 과정을 수행한다. 카메라로부터 영상을 입력받아 Mediapipe 프레임워크를 통해 그림 1과 같이 손가락의 21개 관절 지점 즉 손가락 마디의 좌표(x, y, z)값을 입력 받는다. 입력된 손의 좌표값은 식(1)에 따라 인접한 손 마디의 벡터를 구할 수 있으며, 식(1)에 따라 인접한 손 마디에 연결된 벡터 과 를 이용하여 손가락 마디 사이의 각도를 계산할 수 있다.

> 식(2)에 따라 각각의 인접한 손가락 마디의 단위 벡터를 이용하여 각도 를 계산한 후 단위를 radian에서 degree로 변환 후 손가락 마디의 각도 15개를 출력한다. 손 가락 마디 사이의 각도와 그 각도에 대응하는 제스처의 번호를 csv파일에 저장하여 Training data를 구성하였다. 그림 2에서 A~O열에는 인접한 손가락 마디 사이의 각도가 저장되며, P열에는 손 제스처 인식 숫자가 저장된다. 이렇게 저장된 학습 데이터를 기반으로 실시간으로 입력받은 손 제스처의 종류를 구분할 수 있도록 k-NN 알고리즘을 사용하여 구현하였다. 실시간으로 손의 좌표를 입력받아 각도를 계산하고, 저장된 학습 데이터에서 가장 인접한 데이터의 제스처 종류를 값으로 출력한다.

> 그림 3과 같이 Mediapipe를 이용하여 Training data를 csv 파일 형태로 생성을 하고 실제 카메라 입력 시 사용자 손 제스처 인식 과정을 수행한다. 실시간으로 입력된 이미지에서 계산된 각도를 이용하여 k-NN 알고리즘을 거쳐서 해당 손 제스처 값을 출력한다. 이 과정에서는 k-NN 객체를 생성하여 train함수에 학습 데이터 angle과 gesture를 입력하여 학습한다. 그리고 실시간으로 계산한 15개의 각도 값들을 data 변수에 입력하여 이웃의 값을 찾는 함수에 입력한다. 여기서 k값은 학습 데이터에서 비교할 가장 가까운 값의 개수인데, 손 제스처 모델의 적절한 성능을 위하여 k는 3으로 지정한다. 이에 따라 실시간으로 입력받은 손 이미지의 인접 관절 각도 값들은 학습 데이터에 저장된 각도 값들 중에서 가장 가까운 값 3개를 선택하여 해당 손 제스처를 출력한다. 이미지 입력부터 손 제스처 인식까지 실시간 손 제스처 입력 영상을 이용하여 손 제스처 인식 프로그램이 종료될 때까지 인식할 수 있도록 구현하였다. 그림 4는 카메라에 입력받는 손 제스처 영상을 인식한 결과 화면으로 숫자 0 ~ 5까지 GOOD, BAD, OK 와 같은 의미를 나타내는 손 제스처 인식 결과를 확인할 수 있다. 그리고 추가적으로 다른 의미의 사용자 손 제스처를 인식하고 싶다는 그림 3의 Training data 생성과정을 통해서 추가하여 인식할 수 있다.


## 4장. 시스템 구현 및 실험
4.1 키오스크 제어 알고리즘
> 본 논문에서 구현하는 시스템에서는 키오스크에서 빈번 하게 사용하는 네 가지 제어 동작, 즉 페이지 전후 넘김과 예, 아니오, 특정 메뉴 선택을 제스처로 실현한다. 각 제어 명령에 대응하는 제스처를 표 1에 나타내고 있다.

> 명령에 해당하는 제스처는 노인이 하기 쉬운 제스처로 선정하였다.


 발표자의 일상적인 몸동작과 구별하기 위해서는 제스처의 시작과 끝을 정해둔다. 본 논문에서는 제스처의 시작을 손가락을 모두 펼친 손 모양으로 하고 제스처의 끝을 손가락이 보이지 않는 주먹을 쥔 손 모양으로 한다. 표 2에 나열한 상하좌우의 방향으로 손을 이동하기 전에 발표자는 카메라를 향해 손가락을 펴서 보여주고 나서 제스처를 취한다.

 추가적으로 각 제스처의 인식률을 실험한 결과(표 2)를 보면 'ZERO'의 제스처의 인식률이 현저히 낮은 것을 볼 수 있다. 이는 'GOOD' 제스처와의 혼동에 의한 것인데, 이를 방지하기 위해 'ZERO'와 'GOOD' 제스처는 동일한 화면에서 사용하지 않게끔 하였다.

> 시스템의 제스처 인식부에서는 제스처 인식을 위하여 그림 6에 나타낸 것과 같은 4가지 상태, 즉 입력대기 상태, 입력 상태, 분석 상태, 명령전달 상태를 반복한다. 입력대기 상태에서는 카메라로 들어온 영상에서 손가락의 수를 확인하여 4개 이상이면 입력 상태로 넘어간다.1) 그렇지 않을 경우에는 계속 입력대기 상태에서 손가락 수를 확인한다. 입력 상태에서는 손의 이동 방향을 추적한다. 앞장의 그림 4와 같은 방식으로 현재 위치와 다음 이동 위치를 이용하여방향 벡터를 구한다. 그리고 손가락의 수가 3개 이하가 되면 제스처가 끝난 것으로 간주하고 분석 상태로 넘어간다. 분석 상태에서는 입력 상태에서 추적한 방향 벡터를 분석하여 최종적으로 제스처 방향을 결정한다. 입력된 벡터 수가 적으면 손이 움직이지 않은 것으로 간주하여 입력대기 상태로 돌아간다. 마지막으로 명령전달 상태에서는 제어 명령에 해당하는 키보드 메시지를 생성하여 운영체계로 전달하고 입력대기 상태로 돌아간다.

4.2 웹 소켓 기반 키오스크 제어 가상 설계
> 사용자 손 제스처 인식 알고리즘과 입체 영상 플레이어와의 연동을 통하여 입체 영상 제어 시스템을 설계 및 구현하였다. 파이썬으로 서버와 클라이언트가 서로 특정 포트로 연결되어 실시간으로 양방향 통신을 하는 간단한 제어 시스템을 구현하였다.

4.3 실험 및 결과 분석
> 본 논문에서는 제안하는 시스템의 최적화된 조건을 확인하고자 각기 다른 조건 하에서 인식률 실험을 실시하였다. 실험 방법은 각기 다른 조건을 설정하고 해당 조건 하에서 특정 제스처를 취한 후, 예상 결과와 비교하는 방식이다. 그림 5(?)는 실험 내에서 제스처 비교 및 실험 결과(인식률, 불일치율, 실패율) 출력 기능을 담당한 코드이다. 실험의 조건은 표 5와 같다.

4.3.1 손 각도에 따른 인식률 실험
> 키오스크에 부착될 카메라의 위치에 따라 보여지는 손의 각도가 다르므로 이에 따른 인식률을 비교하여 최적의 위치를 찾고자 하였다. 실험 결과, 표 @에 나타낸 것처럼 ~~

4.3.2 거리에 따른 인식률 실험
> 사용자마다 키오스크 모니터 및 카메라와의 거리가 다르므로 이에 따른 인식률을 비교하여 최적의 위치를 찾고자 하였다. 실험 결과, 표 @에 나타낸 것처럼 ~~

4.3.3 손 방향에 따른 인식률 실험
> 손등, 손바닥, 왼손, 오른손에 따라 인식률이 달라지는지 실험하여 성능을 확인하였다. 실험 결과, 표 @에 나타낸 것처럼 ~~

> 위 실험들을 종합해보았을 때, 최적의 조건은 다음과 같다. ~~~ . 또 세 번째 실험을 통해


## 5장. 결론
> 본 논문은 실시간 손 제스처 인식을 위하여 오픈소스 프레임워크인 MediaPipe 를 활용하여 사용자 손 관절 정보를 획득한 후 머신러닝 k-NN 기법을 활용하여 생성된 학습 모델을 기반으로 구현한 실시간 사용자 손 제스처 인식 알고리즘을 제안하였고, 사용자 인터랙션과 연동이 가능한 소켓 통신 기반 키오스크 제어 시스템을 제안하였다. 본 논문에서는 시스템의 최적 조건을 탐색하기 위하여 방향, 거리, 각도에 따라 실험하였고, 그 결과 @@@ 조건에서 가장 높은 인식률 @@를 얻었다.

> 향후 사용자 손 제스처 인식 알고리즘은 단순 손 제스처 의미 인식에서 손가락의 상대적인 위치 및 영상 내 객체 연동을 고려하여 복잡한 순서도를 가진 키오스크에도 적용할 수 있는 제스처 인식 알고리즘 연구를 진행할 필요가 있다. 본 연구를 통해 노인, 시각장애인 등도 키오스크를 어려움 없이 사용할 수 있게 되어 디지털 격차가 해소되기를 기대한다.