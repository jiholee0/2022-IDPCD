1)

안녕하세요, 노인을 위한 제스처 인식 시스템 설계를 주제로 개별연구를 진행한 이지호입니다.

먼저, 일정이 맞지 않아 부득이하게 비대면으로 발표를 진행하게 된 점 양해 부탁드립니다. 본 연구에서 부족한 점, 개선해야 할 점들을 말씀해주시면 빠르게 반영하도록 하겠습니다. 그럼 지금부터 발표 시작하겠습니다.

2)
3)
본 연구의 세부 목표는 '손동작으로 제어하는 키오스크 시스템 설계하기' 입니다. 

4) 
연구 목적 및 배경은 지난 중간 발표 때 다뤘으니 자세한 설명은 생략하도록 하겠습니다.

~10)
11)
간략하게 말씀드리자면, 노인의 경우 여러가지 원인으로 인해 키오스크 사용에 장벽을 느끼고 있으며, 이를 해결하고자 노인 친화적인 키오스크 시스템을 설계하는 것이 이번 연구의 목적입니다.

12)
13)
본격적으로 연구 진행에 앞서, 본 연구에서 사용될 노인에게 적합한 키오스크 화면을 가상으로 구성하였습니다. 우측의 순서도 속 UI는 
한 화면에는 하나의 질문만,
불필요한 정보나 광고는 과감히 제거,
글씨는 크고 굵게,
외래어보다는 우리말로,
사진과 그림을 적극적으로 활용,
이렇게 크게 다섯 가지의 특징을 갖고 있습니다.

15)
해당 UI에서 쓰이는 동작은 예, 아니오, 선택지 이렇게 3가지 이므로, 각 명령마다 제스처를 할당하여 사용자가 특정 제스처를 취하면 어떤 동작을 수행할지 설정하였습니다. 제스처를 선정할 때에는 사용자가 노인이라는 점과 지난 피드백을 고려하여 최대한 쉽고 단순한 제스처로 선정하였습니다.

16)
키오스크를 제어하는 알고리즘은 다음과 같습니다. 입력 대기 상태, 분석 상태, 데이터 전달 상태, 동작 처리 상태. 이렇게 네 가지의 상태를 반복하고, 최종 화면에 다다르면 시스템을 종료합니다.

17)
제스처 인식에는 Mediapipe와 K-NN 알고리즘을 사용하였습니다.
18)
다음은 데이터 학습 프로세스와 제스처 인식 프로세스를 나타낸 흐름도입니다.

19)
이제 실제 코드 및 결과물을 각 단계에 따라 보여드리겠습니다.

20)
먼저 손 인식 단계입니다. MEDIAPIPE를 이용하여 손 모델을 구축하였고, 인식한 손 모델에 빨간 점과 하얀 선, 손바닥에는 파란 점을 출력하였습니다.

21)
그 다음 제스처 데이터를 수집하였습니다. 특정 제스처를 취했을 때, 손가락 마디의 좌표 값을 추출하고, 이 값을 이용하여 손 마디의 벡터와 각각의 사잇각을 구해 CSV파일로 저장하였습니다. 해당 데이터는 K-NN 알고리즘의 훈련 데이터로 사용되었습니다.

22)
제스처 인식은 앞서 말씀드린 것처럼 K-NN 알고리즘을 활용하였습니다. 훈련 객체를 생성하여 이전 단계에서 생성한 학습 데이터인 각도 값과 제스처를 학습합니다. 그리고 계산한 15개의 각도 값들을 data 변수에 입력하여 이웃한 데이터를 찾습니다.

23)
이후 키오스크 화면을 opencv와 소켓 통신을 활용하여 가상으로 제어해보았습니다. 서버는 클라이언트 접속 시 키오스크의 초기 화면을 띄우고, 이후 서버, 클라이언트, 제스처 인식 시스템, 키오스크 제어 시스템 간의 데이터 전달 및 동작 수행이 순차적으로 이루어지면서 키오스크 화면을 제어합니다.

24)
먼저 클라이언트는 서버와 연결되면 제스처 인식 함수로부터 인식 결과를 받아오고 서버에게 해당 값을 전달합니다.

25)
서버는 클라이언트로부터 받은 제스처 결과를 파라미터로 하여 키오스크 제어 함수를 호출합니다.

26)
키오스크 제어 함수에서는 openCV를 활용하여 주어진 제스처에 따라 동작을 수행합니다. 화면을 전환하거나, 올바르지 않은 제스처가 인식되었다는 결과를 출력하거나, 주문 내역을 저장합니다. 이후 현재 페이지 번호, 처리 완료 여부 데이터를 JSON 형식으로 서버에게 전달합니다.

25)
다시 서버는 키오스크 제어 결과를 받아 클라이언트에게 전달하고

24)
클라이언트는 해당 값을 보고 제스처 인식 함수를 호출합니다.

25)26)27)
이 과정을 반복하고 마지막 페이지까지 도달하여 주문 내역을 출력하는 데모 영상입니다.

28)
29)
제안한 시스템의 최적화된 조건을 확인하고자 각기 다른 조건 하에서 인식률 실험을 실시하였습니다. 카메라의 위치 및 각도 그리고 카메라와 사용자 간 거리를 달리하며 인식률을 비교하였고, 제스처마다의 인식률도 비교하였습니다.

30)
다음은 실험을 진행하는데 쓰인 코드로, 제스처 인식을 반복하고 모든 결과를 종합하여 인식률, 불일치율, 인식 실패율을 출력하는 코드입니다.

31)
먼저, 키오스크에 부착될 카메라의 위치에 따라 보여지는 손의 각도가 다르므로 이에 따른 인식률을 비교하여 최적의 조건을 찾아보았습니다. 시행 횟수는 각 제스처마다 120번씩 수행하였고, 카메라가 키오스크의 아래, 왼쪽, 오른쪽, 위에 있는 경우를 각각 달리 측정하여 비교하였습니다.

32)
그리고, 사용자마다 키오스크 모니터 및 카메라와의 거리가 다르므로 이에 따른 인식률을 비교하여 최적의 조건을 찾아보았습니다. 시행 횟수는 마찬가지로 120번이며, 사용자와 카메라와의 거리가 15cm 이내인 경우, 15cm에서 30cm인 경우, 30cm 인 경우를 나누어 측정하여 비교하였습니다.

33)
첫번째 실험 결과, 카메라가 아래에 설치되어 있는 경우 인식률이 가장 높았습니다. 왼쪽과 오른쪽에서 제스처를 인식하는 경우, 손 모양이 방향에 따라 바뀌는 ‘TWO’, ‘OK’의 인식률이 줄어드는 것을 확인하였습니다. 또한, 카메라가 위에 설치되어 있는 경우 불일치율이 다른 조건보다 높음을 확인하였습니다. 키오스크의 높이가 높은 만큼 위에서 손을 바라보기 때문에 모양이 정확하지 않은 것으로 추정됩니다.

34)
두 번째 실험 결과, 거리가 15cm 이내인 경우 인식률이 가장 높았습니다. 거리가 멀어질수록 인식률이 떨어지고 실패율(손을 인식하지 못하는 경우)이 높아졌습니다. 특히 30cm 이상으로 거리가 멀어지면, 평균 인식률이 84.164%로, 현저히 낮아지는 것을 확인하였습니다.

35)
36)
본 연구는 현재 단순 손 제스처 의미 인식에 그쳤지만, 추후 손가락의 상대적인 위치 및 영상 내 객체 연동을 고려하여 복잡한 순서도를 가진 키오스크에도 적용할 수 있는 제스처 인식 알고리즘 연구를 진행할 필요가 있습니다. 이번 연구를 통해 키오스크 사용에 어려움을 겪는 노인들의 입장에서 생각해볼 수 있었습니다. 그러나 본 연구에서는 키오스크 기계와의 연동, 다양한 키오스크 UI 및 동작을 고려하지 않아 실현 가능성이 적습니다. 처음 계획과는 달리 결과물이 부족하여 아쉽지만 추후 기술력이 더해져 본 연구가 어느 분야이든 활용되기를 바랍니다.

이상으로 발표를 마치도록 하겠습니다. 감사합니다.
 


